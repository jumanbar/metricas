---
title: "Metricas"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Métricas de performance

## Notaciones

- $M_i$ es la _i_-ésima observación de clorofila **medida** in-situ (en $\mu$g/L).

- $E_i$ es la _i_-ésima **estimación** del valor de clorofila hecha (a partir de un _único_ modelo no especificado) (también en $\mu$g/L).

- $E_{i|m}$ es la _i_-ésima estimación del valor de clorofila hecha a partir del modelo $m$ (también en $\mu$g/L).

- $K$ es el conjunto de todos los modelos posibles (o sea, $m \in K$). No usé la letra $M$ porque ya estaba tomada :(

- $mean(M)$, $median(M)$ y $sd(M)$ son el promedio, la mediana y el desvío estándar, respectivamente, del conjunto de valores $M_i$. Análogamente para los $E_{i|m}$. También puede figurar como $median(M_i)$.

- $sign(X)$ es la función signo: 1 si X > 0 y -1 si X < 0

## MWR

**Es el porcentaje de las observaciones en las que "gana" cada modelo**, en donde ganar significa hacer la predicción con menor valor absoluto. La definición matemática sería:

$$MRW (\%) = 100 \times \frac{1}{N} \sum_{i .. N} p(i, m)$$

En donde:

$$ p(i, m) = 
  \begin{cases}
    1 & \quad \text{si } |E_{i|m} - M_i| = min\{|E_{i|m} - M_i|, \forall m \in K\}\\
    0 & \quad \text{en caso contrario}
  \end{cases}
$$

Explicación encontrada en Seegers et al. 2018:

![](explicacion MWR.PNG)


## AEmean

"Mean Absolute Error", tomada de Zhang et al. 2015. Es decir, el error absoluto promedio:

$$AE_{mean} = \frac{1}{N} \sum_{i .. N} |E_i - M_i|$$

## REmean

"Mean Relative Error", tomada de Zhang et al. 2015. El error relativo (a la medición in-situ) promedio:

$$RE_{mean} = \frac{1}{N} \sum_{i .. N} |E_i - M_i|/M_i$$

## DMC

"Standard Deviaton from the Mean", tomada de Zhang et al. 2015... Es decir, qué tan lejos está el promedio de las predicciones, en relación al promedio de las medidas in-situ, normalizado por ese último:

$$DMC (\%) = 100 \times (mean(E) - mean(M)) / mean(M)$$


## DSD

"Standard Deviation of the Standard Deviation", tomada de Zhang et al. 2015. Igual que el anterior, pero con el desvío estándar.

$$DSD (\%) = 100 \times (sd(E) - sd(M)) / sd(M)$$

## Epsilon y Beta

Propuestas por Morley et al. 2018 (ver mail de Nima 18/11/2020). Son la "Median Symmetric Accuracy" (MdSA) y el "Symmetric Signed Percentage Bias".

$$\epsilon (\%) = 100 \times (10 ^ Y - 1) \quad \text{donde} \quad Y = median(|log_{10}(E_i/M_i)|)$$

$$\beta (\%) = 100 \times sign(Z) \times (10 ^ Z - 1) \quad \text{donde} \quad Z = median(log_{10}(E_i/M_i))$$

Nota: $log_{10}(E_i/M_i) = log_{10}E_i - log_{10}M_i$, por lo que estas fórmulas se parecen a las de MAE y Bias encontradas en Pahlevan et al 2019.

- El $\beta$ aumenta linealmente cuando $E > M$, .

```{r}
E <- seq(0.1, 1000, by = 0.1)
b <- E
for (i in 1:length(E)) b[i] <- 100 * beta_(E[i], 100)
plot(E, b, ylab = expression(beta), main = "(M = 100)", type = "l")
abline(v = 100, col = "red")
```

- El $\epsilon$, a diferencia del $\beta$ aumenta rápidamente cuando $E < M$. Aumenta también cuando $E > M$, pero más lentamente, por lo que generalmente es indicador de subestimación.

```{r}
logE <- seq(-1, 3, by = 0.01)
e <- logE
for (i in 1:length(logE)) e[i] <- 100 * epsilon(10 ** logE[i], 100)
plot(10 ** logE, e, type = 'l', ylab = expression(epsilon), main = "(M = 100)",
     xlab = "E")
abline(v = 100, col = "red")
```

```{r}
plot(10 ** logE, e, type = 'l', ylab = expression(epsilon), main = "(M = 100)",
     log = "x", xlab = "E")
abline(v = 100, col = "red")
```

## RMSE y RMSLE

RMSE: Root Mean Squared Error

RMSLE: Root Mean Squared Log Error

$$RMSE = \sqrt{\frac{1}{N} \sum_{i .. N} {(E_i - M_i)^2}}$$

$$RMSLE = \sqrt{\frac{1}{N} \sum_{i .. N} (log_{10}E_i - log_{10}M_i)^2}$$

## MAPE

Median Absolute Percentage Error. Es muy parecido al REmean, pero usa la mediana en lugar del promedio del error relativo:

$$MAPE (\%) = 100 \times median \left( |E_i - M_i|/M_i \right)$$


## Bias

Traducido como sesgo: "log transformed residuals". En su "intención" es parecido al epsilon ($\epsilon$) pero usa el promedio en lugar de la mediana:


$$Bias = 10^Z \quad \text{donde} \quad Z = \frac{1}{N} \sum_{i .. N} (log_{10}E_i - log_{10}M_i)$$

- Bias > 1: sobrestimación  
- Bias < 1: subestimación

## MAE

Mean Absolute Error comuted on log-scale. En su "intención" es parecido al beta ($\beta$) pero usa el promedio en lugar de la mediana:

$$MAE = 10^Y \quad \text{donde} \quad Y = \frac{1}{N} \sum_{i .. N} |log_{10}E_i - log_{10}M_i|$$

## MWRp

Model Win Rate **basado en las métricas de desempeño** (o _performance_). Análogo a MWR, pero esta vez hace un ranking entre modelos basado en un conjunto de métricas de desempeño. Es decir, un MWRp = 50% indica que el modelo $m$ es el mejor para el 50% de las métricas evaluadas.

Se puede expresar en una ecuación para el MWRp de un modelo $m$ determinado, siendo $\omega(E_m)$ el valor de la métrica $\omega$ para el conjunto de estimaciones de Clorofila $E_m$ generadas por el modelo:

$$MRW (\%) = 100 \times \frac{1}{L} \sum_{i .. L} D(\omega)$$

En donde $L$ es el total de métricas incluidas en el cálculo y:

$$ D(\omega) = 
  \begin{cases}
    1 & \quad \text{si } \omega(E_m) \text{ es el mejor desempeño en } \{\omega(E_m), \forall m \in K\}\\
    0 & \quad \text{en caso contrario}
  \end{cases}
$$

Las performances utilizadas en la evaluación de MWRp son AEmean, REmean, RMSE, RMSLE, Beta, Epsilon, MWR, DMC y DSD

- - - 


